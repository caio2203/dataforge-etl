# DataForge ETL Engine ğŸš€

**DataForge** Ã© um motor de ETL (Extract, Transform, Load) de alto desempenho, desenvolvido em C++17 moderno. Projetado do zero com foco em performance e modularidade, o sistema Ã© capaz de processar arquivos de dados em escala de gigabytes, oferecendo uma fundaÃ§Ã£o robusta para pipelines de engenharia de dados complexos.

O projeto nasceu como um estudo aprofundado sobre arquitetura de software de baixo nÃ­vel, gerenciamento de memÃ³ria e os benefÃ­cios de C++ para manipulaÃ§Ã£o de grandes volumes de dados, indo alÃ©m de scripts tradicionais para fornecer uma soluÃ§Ã£o compilada e otimizada.

-----

## ğŸ“‹ Principais CaracterÃ­sticas

  * **NÃºcleo de Alto Desempenho em C++17:** Utiliza recursos modernos de C++ para garantir mÃ¡xima eficiÃªncia e seguranÃ§a no gerenciamento de memÃ³ria, sem a sobrecarga de um garbage collector.
  * **Arquitetura Modular e ExtensÃ­vel:** O design do motor Ã© baseado em uma clara separaÃ§Ã£o de responsabilidades (Extract, Transform, Load), permitindo que novos formatos de dados e transformaÃ§Ãµes sejam adicionados com mÃ­nimo impacto no sistema existente.
  * **ExtraÃ§Ã£o PolimÃ³rfica de Dados:** Suporte nativo para extraÃ§Ã£o de dados de arquivos **CSV** e **JSON** atravÃ©s de uma interface de extraÃ§Ã£o comum, demonstrando o uso eficaz de polimorfismo.
  * **Projetado para Arquivos Gigabytes:** A lÃ³gica de processamento Ã© baseada em *streaming*, lendo os dados linha a linha (ou registro a registro) para manter o consumo de memÃ³ria baixo e constante, independentemente do tamanho do arquivo de entrada.
  * **Roadmap Ambicioso:**
      * **AgregaÃ§Ã£o de Dados (`GROUP BY`):** MÃ³dulo em desenvolvimento para realizar operaÃ§Ãµes de agregaÃ§Ã£o complexas e com estado.
      * **SerializaÃ§Ã£o BinÃ¡ria:** MÃ³dulo planejado para carregar os dados transformados em um formato binÃ¡rio compacto e de leitura rÃ¡pida.
      * **Suporte a Multithreading:** EvoluÃ§Ã£o planejada para paralelizar as etapas de ETL, aproveitando ao mÃ¡ximo os processadores multi-core modernos.

-----

## ğŸ›ï¸ Arquitetura do Projeto

A organizaÃ§Ã£o do DataForge segue as melhores prÃ¡ticas de engenharia de software, com uma clara separaÃ§Ã£o entre interface (`include`), implementaÃ§Ã£o (`src`), testes e outros artefatos. Isso garante um projeto limpo, escalÃ¡vel e de fÃ¡cil manutenÃ§Ã£o.

```
dataforge-etl/
â”œâ”€â”€ src/                # CÃ³digo-fonte (.cpp)
â”‚   â”œâ”€â”€ core/           # Motor principal, pipeline, extratores e fÃ¡brica
â”‚   â”œâ”€â”€ aggregator/     # (Planejado) LÃ³gica de agregaÃ§Ã£o
â”‚   â”œâ”€â”€ serializer/     # (Planejado) LÃ³gica de serializaÃ§Ã£o
â”‚   â””â”€â”€ utils/          # Ferramentas auxiliares
â”œâ”€â”€ include/            # Arquivos de cabeÃ§alho (.h/.hpp)
â”‚   â”œâ”€â”€ common/         # Estruturas de dados comuns (ex: DataRow.h)
â”‚   â”œâ”€â”€ core/           # Interfaces e declaraÃ§Ãµes do motor principal
â”‚   â””â”€â”€ utils/          # DeclaraÃ§Ãµes de ferramentas e bibliotecas de terceiros
â”œâ”€â”€ tests/              # Testes unitÃ¡rios e de integraÃ§Ã£o
â”œâ”€â”€ data/               # Dados de exemplo para teste
â”‚   â”œâ”€â”€ input/          # Arquivos de entrada (CSV, JSON)
â”‚   â””â”€â”€ output/         # Arquivos de saÃ­da gerados
â”œâ”€â”€ build/              # DiretÃ³rio de saÃ­da da compilaÃ§Ã£o (ignorado pelo Git)
â”œâ”€â”€ Makefile            # Automatiza o processo de build
â””â”€â”€ README.md           # Esta documentaÃ§Ã£o
```

-----

## ğŸ› ï¸ Primeiros Passos

### PrÃ©-requisitos

Para compilar e executar o projeto, vocÃª precisarÃ¡ de:

  * Um compilador C++ com suporte a C++17 (ex: `g++` versÃ£o 8 ou superior)
  * `make` para executar a compilaÃ§Ã£o automatizada
  * `git` para clonar o repositÃ³rio

### Compilando e Executando

1.  **Clone o repositÃ³rio:**

    ```bash
    git clone https://github.com/caio2203/dataforge-etl.git
    cd dataforge-etl
    ```

2.  **Compile o projeto:**
    O `Makefile` cuidarÃ¡ de todo o processo de compilaÃ§Ã£o.

    ```bash
    make
    ```

    O executÃ¡vel final serÃ¡ gerado em `build/dataforge`.

3.  **Execute o motor de ETL:**
    Passe o caminho de um arquivo de dados (CSV ou JSON) como argumento.

    ```bash
    # Exemplo com um arquivo CSV
    ./build/dataforge data/input/exemplo.csv

    # Exemplo com um arquivo JSON
    ./build/dataforge data/input/exemplo.json
    ```

-----

## ğŸ—ºï¸ Status e Roadmap

Este projeto estÃ¡ em desenvolvimento ativo.

  - [x] Arquitetura modular e extensÃ­vel definida.
  - [x] Interface de extraÃ§Ã£o de dados (`IDataExtractor`).
  - [x] ImplementaÃ§Ã£o de extrator para **CSV**.
  - [x] ImplementaÃ§Ã£o de extrator para **JSON** (usando a biblioteca nlohmann/json).
  - [x] FÃ¡brica de extratores para seleÃ§Ã£o dinÃ¢mica do formato.
  - [x] Setup de compilaÃ§Ã£o profissional com `Makefile`.
  - [ ] ImplementaÃ§Ã£o do mÃ³dulo `Aggregator` (GROUP BY, SUM, COUNT).
  - [ ] ImplementaÃ§Ã£o do mÃ³dulo `Serializer` para escrita em formato binÃ¡rio.
  - [ ] AdiÃ§Ã£o de suporte a multithreading no pipeline de ETL.
  - [ ] CriaÃ§Ã£o de uma suÃ­te de testes unitÃ¡rios.

-----

## ğŸ¤ Como Contribuir

ContribuiÃ§Ãµes sÃ£o bem-vindas\! Se vocÃª tem ideias para novas funcionalidades, melhorias de performance ou correÃ§Ãµes de bugs, por favor, siga estes passos:

1.  FaÃ§a um "Fork" do repositÃ³rio.
2.  Crie uma nova branch para sua feature (`git checkout -b feature/minha-feature`).
3.  FaÃ§a o commit de suas alteraÃ§Ãµes (`git commit -m 'Adiciona minha-feature'`).
4.  Envie para a sua branch (`git push origin feature/minha-feature`).
5.  Abra um "Pull Request".

-----

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.