# DataForge ETL Engine ğŸš€

**DataForge** Ã© um motor de ETL (Extract, Transform, Load) de alto desempenho, desenvolvido em C++17 moderno. Projetado do zero com foco em performance e modularidade, o sistema Ã© capaz de processar arquivos de dados de mÃºltiplos formatos (CSV, JSON) em escala de gigabytes, oferecendo uma fundaÃ§Ã£o robusta para pipelines de engenharia de dados complexos e carregando os resultados em um formato binÃ¡rio de alta performance.

O projeto nasceu como um estudo aprofundado sobre arquitetura de software de baixo nÃ­vel, gerenciamento de dependÃªncias (`Git Submodules`) e os benefÃ­cios de C++ para manipulaÃ§Ã£o de grandes volumes de dados.

-----

## ğŸ“‹ Principais CaracterÃ­sticas

  * **NÃºcleo de Alto Desempenho em C++17:** Utiliza recursos modernos de C++ para garantir mÃ¡xima eficiÃªncia e seguranÃ§a no gerenciamento de memÃ³ria, sem a sobrecarga de um garbage collector.
  * **Arquitetura Modular e ExtensÃ­vel:** O design do motor Ã© baseado em uma clara separaÃ§Ã£o de responsabilidades (Extract, Transform, Load), permitindo que novos formatos e transformaÃ§Ãµes sejam adicionados com mÃ­nimo impacto.
  * **ExtraÃ§Ã£o PolimÃ³rfica de Dados:** Suporte nativo para extraÃ§Ã£o de dados de arquivos **CSV** e **JSON** atravÃ©s de uma interface de extraÃ§Ã£o comum, demonstrando o uso eficaz dos padrÃµes de projeto *Strategy* e *Factory*.
  * **Carregamento (Load) em Formato BinÃ¡rio:** IntegraÃ§Ã£o com a biblioteca externa **[fast-serializer](https://github.com/caio2203/fast-serializer)** para salvar os dados processados em um formato binÃ¡rio customizado, resultando em arquivos de saÃ­da compactos e de leitura extremamente rÃ¡pida.
  * **Projetado para Arquivos Gigabytes:** A lÃ³gica de processamento Ã© baseada em *streaming*, lendo os dados registro a registro para manter o consumo de memÃ³ria baixo e constante.
  * **Gerenciamento de DependÃªncias com Git Submodules:** Demonstra uma abordagem profissional para integrar bibliotecas externas, mantendo os projetos desacoplados e versionados.

-----

## ğŸ›ï¸ Arquitetura do Projeto

A organizaÃ§Ã£o do DataForge segue as melhores prÃ¡ticas de engenharia de software, com uma clara separaÃ§Ã£o entre interface (`include`), implementaÃ§Ã£o (`src`), dependÃªncias (`vendor`), testes e outros artefatos.

```
dataforge-etl/
â”œâ”€â”€ vendor/             # DependÃªncias externas (via Git Submodules)
â”‚   â””â”€â”€ fast-serializer/
â”œâ”€â”€ src/                # CÃ³digo-fonte (.cpp)
â”‚   â”œâ”€â”€ core/           # Motor principal, pipeline, extratores, loader e fÃ¡brica
â”‚   â”œâ”€â”€ aggregator/     # (Planejado) LÃ³gica de agregaÃ§Ã£o
â”‚   â””â”€â”€ ...
â”œâ”€â”€ include/            # Arquivos de cabeÃ§alho (.h/.hpp)
â”‚   â”œâ”€â”€ common/         # Estruturas de dados comuns (ex: DataRow.h)
â”‚   â”œâ”€â”€ core/           # Interfaces e declaraÃ§Ãµes do motor principal
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/              # Testes unitÃ¡rios e de integraÃ§Ã£o
â”œâ”€â”€ data/               # Dados de exemplo para teste
â”‚   â”œâ”€â”€ input/          # Arquivos de entrada (CSV, JSON)
â”‚   â””â”€â”€ output/         # Arquivos de saÃ­da gerados (.dfb)
â”œâ”€â”€ build/              # DiretÃ³rio de saÃ­da da compilaÃ§Ã£o (ignorado pelo Git)
â”œâ”€â”€ .gitmodules         # Arquivo de configuraÃ§Ã£o do submÃ³dulo
â”œâ”€â”€ Makefile            # Automatiza o processo de build
â””â”€â”€ README.md           # Esta documentaÃ§Ã£o
```

-----

## ğŸ› ï¸ Primeiros Passos

### PrÃ©-requisitos

Para compilar e executar o projeto, vocÃª precisarÃ¡ de:

  * Um compilador C++ com suporte a C++17 (ex: `g++` versÃ£o 8 ou superior)
  * `make` para executar a compilaÃ§Ã£o automatizada
  * `git` para clonar o repositÃ³rio

### Compilando e Executando

1.  **Clone o repositÃ³rio (incluindo o submÃ³dulo):**
    Use a flag `--recurse-submodules` para clonar o projeto principal e todas as suas dependÃªncias de uma sÃ³ vez.

    ```bash
    git clone --recurse-submodules https://github.com/caio2203/dataforge-etl.git
    cd dataforge-etl
    ```

    *(Se vocÃª jÃ¡ clonou sem a flag, pode inicializar o submÃ³dulo com `git submodule update --init --recursive`)*

2.  **Compile o projeto:**
    A `Makefile` cuidarÃ¡ de todo o processo, incluindo a compilaÃ§Ã£o da biblioteca `fast-serializer`.

    ```bash
    make
    ```

    O executÃ¡vel final serÃ¡ gerado em `build/dataforge`.

3.  **Execute o motor de ETL:**
    O programa agora espera **dois argumentos**: o arquivo de entrada e o nome do arquivo de saÃ­da.

    ```bash
    # Exemplo com um arquivo CSV
    ./build/dataforge data/input/vendas.csv data/output/resultado.dfb

    # Exemplo com um arquivo JSON
    ./build/dataforge data/input/dados.json data/output/resultado.dfb
    ```

    ApÃ³s a execuÃ§Ã£o, um novo arquivo binÃ¡rio (`resultado.dfb`) serÃ¡ criado na pasta `data/output/`.

-----

## ğŸ—ºï¸ Status e Roadmap

Este projeto estÃ¡ em desenvolvimento ativo.

  - [x] Arquitetura modular e extensÃ­vel definida.
  - [x] Interface de extraÃ§Ã£o de dados (`IDataExtractor`).
  - [x] ImplementaÃ§Ã£o de extrator para **CSV** e **JSON**.
  - [x] Desenvolvimento da biblioteca **`fast-serializer`** em repositÃ³rio separado.
  - [x] **IntegraÃ§Ã£o** da biblioteca via `Git Submodules` para a etapa de **Load**.
  - [x] Pipeline E-\>L (Extract-\>Load) funcional.
  - [ ] ImplementaÃ§Ã£o do mÃ³dulo `Aggregator` (a etapa **Transform**).
  - [ ] AdiÃ§Ã£o de suporte a multithreading no pipeline de ETL.
  - [ ] CriaÃ§Ã£o de uma suÃ­te de testes unitÃ¡rios com GTest.

-----

## ğŸ¤ Como Contribuir

ContribuiÃ§Ãµes sÃ£o bem-vindas\! Se vocÃª tem ideias para novas funcionalidades, melhorias de performance ou correÃ§Ãµes de bugs, por favor, siga estes passos:

1.  FaÃ§a um "Fork" do repositÃ³rio.
2.  Crie uma nova branch para sua feature (`git checkout -b feature/minha-feature`).
3.  FaÃ§a o commit de suas alteraÃ§Ãµes (`git commit -m 'Adiciona minha-feature'`).
4.  Envie para a sua branch (`git push origin feature/minha-feature`).
5.  Abra um "Pull Request".

-----

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.