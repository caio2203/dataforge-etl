# DataForge ETL Engine ğŸš€

**DataForge** Ã© um motor de ETL (Extract, Transform, Load) de alto desempenho, desenvolvido em C++17 moderno. Projetado do zero com foco em performance e modularidade, o sistema Ã© capaz de processar arquivos de dados de mÃºltiplos formatos (CSV, JSON) em escala de gigabytes, oferecendo uma fundaÃ§Ã£o robusta para pipelines de engenharia de dados complexos e carregando os resultados em um formato binÃ¡rio de alta performance.

O projeto nasceu como um estudo aprofundado sobre arquitetura de software de baixo nÃ­vel, concorrÃªncia, gerenciamento de dependÃªncias (`Git Submodules`) e os benefÃ­cios de C++ para manipulaÃ§Ã£o de grandes volumes de dados.

-----

## ğŸ“‹ Principais CaracterÃ­sticas

  * **NÃºcleo de Alto Desempenho em C++17:** Utiliza recursos modernos de C++ para garantir mÃ¡xima eficiÃªncia e seguranÃ§a no gerenciamento de memÃ³ria, sem a sobrecarga de um garbage collector.
  * **Arquitetura Modular e ExtensÃ­vel:** O design do motor Ã© baseado em uma clara separaÃ§Ã£o de responsabilidades (Extract, Transform, Load), permitindo que novos formatos sejam adicionados com mÃ­nimo impacto.
  * **Processamento Paralelo (Multithreading):** O pipeline de ETL foi re-arquitetado com o padrÃ£o **Produtor-Consumidor**, usando `std::thread` para que as etapas de ExtraÃ§Ã£o e TransformaÃ§Ã£o/Carga ocorram em paralelo, otimizando o uso de I/O e CPU.
  * **ExtraÃ§Ã£o PolimÃ³rfica de Dados:** Suporte nativo para extraÃ§Ã£o de dados de arquivos **CSV** e **JSON** atravÃ©s de uma interface de extraÃ§Ã£o comum, demonstrando o uso eficaz dos padrÃµes de projeto *Strategy* e *Factory*.
  * **Motor de AgregaÃ§Ã£o (Transform):** Implementa a lÃ³gica de transformaÃ§Ã£o principal, realizando agregaÃ§Ãµes complexas (`GROUP BY`, `SUM`, `COUNT`, `AVG`) em memÃ³ria de forma eficiente com `std::unordered_map`.
  * **Carregamento (Load) em Formato BinÃ¡rio:** IntegraÃ§Ã£o com a biblioteca externa **[fast-serializer](https://github.com/caio2203/fast-serializer)** para salvar os dados processados em um formato binÃ¡rio customizado, resultando em arquivos de saÃ­da compactos e de leitura extremamente rÃ¡pida.
  * **Projetado para Arquivos Gigabytes:** A lÃ³gica de processamento Ã© baseada em *streaming*, lendo os dados registro a registro para manter o consumo de memÃ³ria baixo e constante.

-----

## ğŸ›ï¸ Arquitetura do Projeto

A organizaÃ§Ã£o do DataForge segue as melhores prÃ¡ticas de engenharia de software, com uma clara separaÃ§Ã£o entre interface (`include`), implementaÃ§Ã£o (`src`), dependÃªncias (`vendor`), testes e outros artefatos.

```
dataforge-etl/
â”œâ”€â”€ vendor/             # DependÃªncias externas (via Git Submodules)
â”‚   â””â”€â”€ fast-serializer/
â”œâ”€â”€ src/                # CÃ³digo-fonte (.cpp)
â”‚   â”œâ”€â”€ core/           # Motor principal, pipeline, extratores, loader e fÃ¡brica
â”‚   â”œâ”€â”€ aggregator/     # MÃ³dulo de TransformaÃ§Ã£o (agregaÃ§Ã£o GROUP BY)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ include/            # Arquivos de cabeÃ§alho (.h/.hpp)
â”‚   â”œâ”€â”€ common/         # Estruturas de dados comuns (ex: DataRow.h)
â”‚   â”œâ”€â”€ core/           # Interfaces e declaraÃ§Ãµes do motor principal
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/              # (Planejado) Testes unitÃ¡rios e de integraÃ§Ã£o
â”œâ”€â”€ data/               # Dados de exemplo para teste
â”‚   â”œâ”€â”€ input/          # Arquivos de entrada (CSV, JSON)
â”‚   â””â”€â”€ output/         # Arquivos de saÃ­da gerados (.dfb)
â”œâ”€â”€ build/              # DiretÃ³rio de saÃ­da da compilaÃ§Ã£o (ignorado pelo Git)
â”œâ”€â”€ .gitmodules         # Arquivo de configuraÃ§Ã£o do submÃ³dulo
â”œâ”€â”€ Makefile            # Automatiza o processo de build
â””â”€â”€ README.md           # Esta documentaÃ§Ã£o
```

-----

## ğŸ› ï¸ Primeiros Passos

### PrÃ©-requisitos

Para compilar e executar o projeto, vocÃª precisarÃ¡ de:

  * Um compilador C++ com suporte a C++17 e `pthreads` (ex: `g++` versÃ£o 8 ou superior)
  * `make` para executar a compilaÃ§Ã£o automatizada
  * `git` para clonar o repositÃ³rio

### Compilando e Executando

1.  **Clone o repositÃ³rio (incluindo o submÃ³dulo):**

    ```bash
    git clone --recurse-submodules https://github.com/caio2203/dataforge-etl.git
    cd dataforge-etl
    ```

2.  **Compile o projeto:**

    ```bash
    make
    ```

    O executÃ¡vel final serÃ¡ gerado em `build/dataforge`.

3.  **Execute o motor de ETL:**
    O programa espera dois argumentos: o arquivo de entrada e o nome do arquivo de saÃ­da.

    ```bash
    # Exemplo com um arquivo CSV
    ./build/dataforge data/input/vendas.csv data/output/resultado.dfb
    ```

-----

## ğŸ—ºï¸ Status e Roadmap

Este projeto estÃ¡ completo.

  - [x] Arquitetura modular e extensÃ­vel definida.
  - [x] Interface de extraÃ§Ã£o de dados (`IDataExtractor`).
  - [x] ImplementaÃ§Ã£o de extrator para **CSV** e **JSON**.
  - [x] Desenvolvimento da biblioteca **`fast-serializer`** em repositÃ³rio separado.
  - [x] IntegraÃ§Ã£o da biblioteca via `Git Submodules` para a etapa de **Load**.
  - [x] ImplementaÃ§Ã£o do mÃ³dulo **`Aggregator`** (a etapa **Transform**).
  - [x] AdiÃ§Ã£o de suporte a **multithreading** no pipeline de ETL.
  - [x] Pipeline E-\>T-\>L (Extract-\>Transform-\>Load) completo e funcional.

-----

## ğŸ¤ Como Contribuir

ContribuiÃ§Ãµes sÃ£o bem-vindas\! Se vocÃª tem ideias para novas funcionalidades, melhorias de performance ou correÃ§Ãµes de bugs, por favor, siga estes passos:

1.  FaÃ§a um "Fork" do repositÃ³rio.
2.  Crie uma nova branch para sua feature (`git checkout -b feature/minha-feature`).
3.  FaÃ§a o commit de suas alteraÃ§Ãµes (`git commit -m 'Adiciona minha-feature'`).
4.  Envie para a sua branch (`git push origin feature/minha-feature`).
5.  Abra um "Pull Request".

-----

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.